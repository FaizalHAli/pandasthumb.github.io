---
layout: article
title: Extended trolley problem
date: '2015-10-28 19:56:25 -0700'
mt_id: 7138
blog_id: 2
post_id: 7138
basename: extended_trolle
---
I just ran across this article, <a href="http://www.iflscience.com/technology/should-self-driving-car-be-programmed-kill-its-passengers-greater-good-scenario">Should a self-driving car kill its passengers in a "greater good" scenario?</a> Though the article does not say so, it is the <a href="https://en.wikipedia.org/wiki/Trolley_problem">trolley problem</a>, but with a twist: You are the driver of the trolley, and you have to ask whether <i>you</i> ought to be sacrificed for the greater good.  That is, there are now three possibilities, not two: do nothing and kill five people; swerve and kill one; or (the added possibility) swerve and kill yourself. Any thoughts?
