---
layout: article
title: What is Complexity?
date: '2007-11-25 14:23:17 -0700'
author: PvM
mt_id: 3425
blog_id: 2
post_id: 3425
basename: what_is_complex
published: false
---
I hope to review a variety of resources on the issue of complexity, especially as it may apply to biology and show that contrary to some <url href="http://www.uncommondescent.com/the-design-of-life/we-have-the-hat-but-where%e2%80%99s-that-rabbit-high-levels-of-information-in-simple-life-forms/">ill informed opinions</url>, scientists have been showing how information can trivially increase in the genome under processes or regularity and chance.

As Jeffrey Shallit pointed out in his <url href="http://www.no-free-lunch.org/Shal02.pd">review of Dembski's "No Free Lunch"

<quote>Poor scholarship. 

For a book that purports to discuss fundamental questions about information, complexity, and biology, there is remarkably little discussion or awareness of previous work. Dembski does not cite any of the following works, just to list a few:

Kimura’s paper where he shows how natural selection can increase Shannon information (Kimura, 1961);

Wicken’s book on evolution and information (Wicken, 1987);

The papers of Saunders and Ho (Saunders and Ho, 1976; Saunders and Ho, 1981) that argue that complexity increases during evolution;

The paper of Nehaniv and Rhodes (1997) showing how, in a finite automaton model, complexity can evolve in biological systems.

The field of artificial life evidently poses a significant challenge to Dembski’s claims about the failure of evolutionary algorithms to generate complexity. Indeed, artificial life researchers regularly find their simulations of evolution producing the sorts of novelties and increased complexity that Dembski claims are impossible. Yet NFL’s coverage of artificial life is limited to a few dismissive remarks, the longest of which I have already quoted above. Indeed, the term "artificial life" does not even appear in NFL’s index. There is no reference to, for example, the work of Adami, Ofria, and Collier (2000) which suggests the possibility of increased complexity over time.

As a scholarly work, Dembski’s NFL falls dramatically short
</quote>

<url href="http://books.google.com/books?id=BQWrppy8ooIC">The Evolution of Complexity: The Violet Book of "Einstein Meets Magritte"</url>  By Alexander Riegler, Francis Heylighen, Johan Bollen, Springer 1999

<url href="http://bruce.edmonds.name/">Bruce Edmonds</url> described as early as 1995 how Intelligent Design has defined complexity although he may not have been aware of the ID movement at that time. Bruce also used to maintain a large list of relevant <url href="http://bruce.edmonds.name/combib/evolution.html">references</url> and other <url href="http://bruce.edmonds.name/complink.html">complexity related links</url>

<quote>Ignorance 
The use of complexity to describe systems of which we are necessarily ignorant has close 
connections to the use of complexity as a paradigm. Examples might be “The brain is too complex for us 
to understand” or “as we understand more about chaotic systems, the boundary of complexity recedes”. 
Complexity can be a cause of ignorance, but to completely associate the two assumes that there are not 
any other significant causes. It is not very helpful to describe the internal state of an electron as complex 
just because we are ignorant about it. 
</quote>
<url href="http://bruce.edmonds.name/evolcomp/">What is Complexity?  - The philosophy of  complexity per se with application to some examples in evolution. </url> in F. Heylighen & D. Aerts (Eds.): The Evolution of Complexity, Kluwer, Dordrecht.


I will start with an list of relevant literature (incomplete)

<url href="http://www.cs.toronto.edu/~mackay/README.html">David McKay</url> Professor of Natural Philosophy Department of Physics  Cavendish Laboratory, University of Cambridge.

1. Natural selection as the process of accumulating genetic information in adaptive evolution, M. Kimura (1961)
2. Rate of Information Acquisition by a Species subjected to Natural Selection, D.J.C. MacKay
3. Evolution of biological information, T.D. Schneider
4. The fitness value of information, C.T. Bergstrom and M. Lachmann
5. Review of W. Dembski’s No Free Lunch, J. Shallit
6. The Evolution and Understanding of Hierarchical Complexity in Biology from an Algebraic Perspective, C.L. Nehaniv and J.L. Rhodes
7. On the Increase in Complexity in Evolution, P.T. Saunders and M.W. Ho (1976)
8. On the Increase in Complexity in Evolution II: The Relativity of Complexity and the Principle of Minimum Increase, P.T. Saunders and M.W. Ho (1981)

    * Kampis,G; Csanyi,V; 1987, Notes on Order and Complexity, Journal of Theoretical Biology, 124, 111-121
    * Kampis,G; Csanyi,V; 1985, Simple Models Do Not Eliminate Complexity from the Real World, Journal of Theoretical Biology, 115, 467-469
    * Hinegardner,R; Engelberg,J; 1983, Biological Complexity, Journal of Theoretical Biology, 104, 7-20
    * Saunders,PT; Ho,MW; 1981, On the Increase in Complexity in Evolution, Journal of Theoretical Biology, 90, 515-530
    * Papentin,F; 1980, On Order and Complexity, Journal of Theoretical Biolo


<url href="http://www.krl.caltech.edu/~adami/cas.html">Chris Adami at Caltech</url>


The complexity of symbolic sequences C. Adami and N. Cerf

We introduce a practical measure for the complexity of sequences of symbols (``strings'') that is rooted in automata theory but avoids the problems of Kolmogorov-Chaitin complexity. This physical complexity can be estimated for ensembles of sequences, for which it reverts to the difference between the maximal entropy of the ensemble and the actual entropy given the specific environment within which the sequence is to be interpreted. Thus, the physical complexity measures the amount of information about the environment that is coded in the sequence, and is conditional on such an environment. In practice, an estimate of the complexity of a string can be obtained by counting the number of loci per string that are fixed in the ensemble, while the volatile positions represent, again with respect to the environment, randomness. We apply this measure to tRNA sequence data.

<url href="http://xxx.lanl.gov/abs/adap-org/9605002">Physical complexity of symbolic sequences (2000)</url>

We applied this measure of complexity to study the evolution of complexity in

<url href="http://xxx.lanl.gov/abs/physics/0005074">Evolution of Biological Complexity (2000)</url>

Complexity measures (including physical complexity), are reviewed in

<url href="http://www.krl.caltech.edu/~adami/Complexity2002.pdf"> Sequence Complexity in Darwinian Evolution (2002)</url>
<url href="http://www.krl.caltech.edu/~adami/BE2002.pdf">What is Complexity? (2002)</url>


<quote>
<b>Abstract</b>
Arguments for or against a trend in the evolution of complexity are weakened by the lack of an unambiguous definition of complexity. Such definitions abound for both dynamical systems and biological organisms, but have drawbacks of either a conceptual or a practical nature. Physical complexity, a measure based on automata theory and information theory, is a simple and intuitive measure of the amount of information that an organism stores, in its genome, about the environment in which it evolves. It is argued that physical complexity must increase in molecular evolution of asexual organisms in a single niche if the environment does not change, due to natural selection. It is possible that complexity decreases in co-evolving systems as well as at high mutation rates, in sexual populations, and in time-dependent  landscapes. However, it is reasoned that these factors usually help, rather than hinder, the evolution of complexity, and that a theory of physical complexity for co-evolving species will reveal an overall trend towards higher complexity in biological evolution.  
</quote>

Christoph Adami,  <url href="http://www.krl.caltech.edu/~adami/Complexity2002.pdf">What is complexity?</url> BioEssays  24:1085 – 1094, 2002. 

<!--more-->

<quote>
Often, these camps disagree not only about the existence of a trend, but also on what type of complexity measure to use, and whether maximum or average complexity is pertinent. Most agree however that nobody knows precisely what is meant by the word ‘‘complexity’’ when referring to a biological organism. Indeed, while complexity measures abound (many of them invented by physicists, Ref. 2), their relationship to biology is not always clear. I will review here several different kinds of complexity measures (without trying to be exhaustive), and then focus on a recent measure that appears to capture what we intuitively expect from such a measure in biology, and discuss what it implies about a trend in the evolution of complexity. 
</quote>


<url href="http://octavia.zoology.washington.edu/publications/working/BergstromAndLachmann05.pdf">The fitness value of information</url>  by <url href="http://octavia.zoology.washington.edu/publications/">Carl T. Bergstrom </url>

<quote>
The disconnect between entropy and mutual information on one hand and the value of information on the other has long puzzled biologists in general and the authors of this paper in particular. Entropy and mutual information appear  to measure information quantity while reflecting nothing about fitness consequences; the value of information measures fitness consequences but has nothing to do with the actual length or information quantity of a message. But early work in population genetics [11, 12, 13, 14]1 and recent analyses of evolution in fluctuating environments [17, 18] hint at a possible relation between information and fitness. What is this relation? Information theorists since Kelly [19] have observed that in special circumstances, information value and information-theoretic measures may be related. Here we argue that these special circumstances are exactly those about which biologists should be most concerned: the  context of evolution by natural selection. We address the question “how much is information worth to living organisms?” and show that the answer turns out to be a striking amalgam of mutual information and the decision-theoretic value of information. 
</quote>
