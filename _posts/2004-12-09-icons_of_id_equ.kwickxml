---
layout: article
title: 'Icons of ID: Equivocation on design'
date: '2004-12-09 22:43:50 -0700'
author: PvM
mt_id: 598
blog_id: 2
post_id: 598
basename: icons_of_id_equ
---
Intelligent Design proponents often pull a bait and switch when discussing the detection of design. On the one hand they argue that ID contributes to science since it adds the concept of design to science, on the other hand when pressed for examples to support their claims, they point to science making successful design inferences as evidence of the validity of design detection.
How can this be? On the one hand ID is portrayed as adding something to science, on the other hand science is argued to already have these concepts. 

Of course ID proponents further muddle the issues by confusing Dembski's design inference as being relevant to how science detects design. On ARN, Salvador is showing all the signs of these confusions as he tries in vain to address the critiques raised by Dayton, Charlie and RBH.

<!--more-->

<b>Equivocation/Bait and Switch</b>

Don't you love the equivocation between 'design inference' ala Dembski which is clearly based on an argument from ignorance 'Not X thus Y' and the 'design inference' used to recognize Mt Rushmore as 'designed' which is based on what we DO know. However with the flagellum there is NO knowledge about the designer(s) which would allow us to formulate a scientific design hypothesis. As Richard Wein has pointed out it serves ID thus to exaggerate the <a href="http://www.designinference.com/documents/2002.09.Van_Till_Response.htm">ignorance of science and scientists</a> since only this way can a design inference succeed. 

Salvador on ARN is engaging in a similar <a href="http://www.arn.org/ubb/ultimatebb.php?ubb=get_topic;f=13;t=001727;p=8">bait and switch</a> when he quotes Dembski and argues

<quote>
The Explanatory Filter formalizes ordinary human practice so that we can take that formalization and create other instances of the explanatory filter in a more rigourous way.

<b>Dembski in Debating Design:</b>
<i>Certainly in special sciences ranging from forensics to archaeology to SETI, appeal to a designing intelligence is indeispensable. What's more, within these sciences there are well-developed techniques for identifying intelligence. What if the techniques could be formalized and applied to biological systems?</i>

IDists are taking well developed techniques and trying to formalize them. The process of formalization creates an archytype from which other instances of the EF can be created.
</quote>

Of course Salvador now has a problem since on the one hand he is arguing that ID adds something to science namely the detection of 'design' but on the other hand he is arguing that science already does this. So what exactly is it that ID has to offer to science? Nothing really... All it claims is that it tries to formalize how design is inferred already but its formalization is flawed as it does not match how design is commonly inferred and since it is totally unsuitable for detecting new design (Del Ratzsch).

In other words, either ID has to accept that science already includes design and thus ID's claims that it adds something to science which was missing are false or ID argues that it does add something new (and flawed) but then it cannot appeal to detection of human design in criminology, archaeoloy etc since that would require ID to accept the 'means, motives and opportunity' approach. ID has to avoid dealing with constraining its designer and thus cannot really claim any similarity to how science applies design detection.

RBH wrote an <a href="http://www.arn.org/ubb/ultimatebb.php?ubb=get_topic;f=13;t=001727;p=8">excellent overview of the problems</a>  with these claims .

<quote>
Now Salvador claims that analogy applies to the varieties of Explanatory Filter:  

<hr/>
<i>Quote:

The EF abstraction encompasses:

1. Ordinary Human Practice of Detecting Design
2. Detection methods involving careful statements of probability and specification
</i>
<hr/>

In this instance one is up the river if one tries to isomorphically map one onto the other.  Their relationship, if any, is not of logical structure -- "form."  If they are members of the same class, class membership is based on something besides their logical form.  The only thing they have in common is that they both purportedly detect "design."  But then the argument that because humans can detect design, the Explanatory Filter formalism detects design fails.  That one instrument detecets a phenomenon does not provide an argument that a very different instrument can detect a different phenomenon with the same name.  Detecting human designs using a subjective human to do the detecting is not the same as using a formal probabilitistic procedure.

Further, humans are not infrequently mistaken when we "detect" design.  A lovely example is the Face on Mars:
<img src="http://www.msss.com/education/facepage/face_icon.gif"/>

When Viking Orbiter I first transmitted this image, it was immediately interpreted by many as displaying "design," that it was artificially sculpted.  
<a href="http://www.viewzone.com/marsface.html">Some people</a> explicitly identified Mt. Rushmore as what amounts to a 'specification' for it:  

<hr/>
<i>Quote:

But the question is one of artificiality, not of meaning. The "face" has a sufficient number of anomalous properties to tilt the evidence in favor of artificiality, regardless of what its artistic purposes are. Consider Mount Rushmore in a thousand or 10,000 years...would it be clear who or what it memorialized? Probably not. But evidence of its carved nature would probably be evident. The case may be the same for the "face."
</i>
<hr/>

Subsequent photographs over the years showed that the 'Face on Mars' is a natural geological phenomenon.  <a href=""http://www.space.com/scienceastronomy/solarsystem/mars_face_010525-1.html"">Here's one such</a> photograph, a recontructed 3-D view using laser altimeter data:

<img src="http://www.space.com/images/h_marsface_3D_010525_02.jpg"/>

Another stimulus for mistaken attribution of design is the Happy Face crater:
<img src="http://www.msss.com/education/happy_face/happy_logo.gif"/>

So, "intuitive specifications" are not all that reliable.  False positives are easily possible.  <a href="http://www.mufor.org/ares/index.html">Some people</a> <i>still</i> believe that the "face on Mars is artificial and that there are additional "designed" structures on Mars.

How about the probability part?  Again, humans are not real good at subjectively estimating probabilities.  The names to start with are Tversky and Kahneman.  (Kahneman won the Nobel Memorial Prize in Economics in 2002 for his work on decision-making under uncertainty.  Tversky would surely have shared it had he not died before the award.)   A <a href="http://www.cog-tech.com/papers/chapters/biases/biases.doc">review is here</a>.  I don't have the time nor inclination to type it all out.

The bottom line is that human "design detection" is plagued with errors in "specifications" and unreliable probability estimates.  Various biases (e.g., availability, representativeness, base rate mis-estimation, and so on) make us unreliable design detectors in any but the most ordinary situations.  But we also readily 'detect' design where there is none.
All that said, the question remains: where is an example of the use of the Explanatory Filter on a biological phenomenon, performed as it was formalized by Dembski in <i>The Design Inference</i>?  Nowhere to be seen, for all of Salvador's verbiage, parlor games with dice, and subjective smearing out of the notion of "explanatory filter."
</quote>


<b>Equivocation on the term complexity</b>

The term specified complexity as used by Dembski is not a typical measure of complexity but rather describes the probability that a particular chance/regularity pathway can explain a particular event. When our ignorance prevents us from providing for such measures, ID typically resorts to strawman calculations which exaggerate the ignorance (Dembski's protein calculations come to mind) and thus concludes that given a particular (strawman hypothesis) we have shown that there is complexity (low probability) and since we 'know' (although this is never formalized) that intelligent designers can do almost anything, we thus can conclude that it was intelligently designed. In other words 'Not X thus Y'. No effort is made to present evidence that an intelligent designer is a better explanation, just that given our present knowledge we 'don't know' how it may have happened thus we conclude 'intelligently designed'.
It's exactly this approach to using the design inference which makes it susceptible to false positives.
